{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = data.iloc[0:int(0.7*len(data))]\n",
    "cv_data = data.iloc[int(0.7*len(data)):int(0.9*len(data))]\n",
    "testing_data = data.iloc[int(0.9*len(data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_T = training_data.drop(['id','diagnosis',data.columns[32]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dash_T = X_T - np.mean(X_T,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dash_T = np.array(X_dash_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dash_T = X_dash_T/np.std(X_dash_T,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dash_T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = np.cov(X_dash_T,rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_factors = np.linalg.svd(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_factors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = sigma_factors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_matrix = Q[:,0:3].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_matrix = Q[:,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(decoding_matrix,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.matmul(encoding_matrix,decoding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = [None,X_dash_T.shape[1],3,X_dash_T.shape[1]]\n",
    "theta_hat_initial = [None,None,np.random.randn(neurons[1],neurons[2]),\n",
    "                     np.random.randn(neurons[2],neurons[3])]\n",
    "H = [None]*len(neurons)\n",
    "activation = [None,None,\"relu\",\"relu\"]\n",
    "frwrd_dels = [None]*len(neurons)\n",
    "backwrd_dels = [None]*len(neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def G(theta_hat_l,Hl_minus1):\n",
    "    return np.matmul(theta_hat_l.T,Hl_minus1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(theta_hat_l,Hl_minus1,a):\n",
    "    if a == \"linear\":\n",
    "        return G(theta_hat_l,Hl_minus1)\n",
    "    elif a == \"sigmoid\":\n",
    "        return 1/(1 + np.exp(-G(theta_hat_l,Hl_minus1)))\n",
    "    elif a == \"softmax\":\n",
    "        layer_activation = np.array([np.exp(glc)/np.sum(np.exp(G(theta_hat_l,Hl_minus1)))\n",
    "                        for glc in G(theta_hat_l,Hl_minus1)])\n",
    "        return layer_activation.reshape(layer_activation.shape[0],1)\n",
    "    elif a == \"relu\":\n",
    "        return (G(theta_hat_l,Hl_minus1) > 0)*G(theta_hat_l,Hl_minus1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_prime(theta_hat_l,Hl_minus1,a):\n",
    "    if a == \"linear\":\n",
    "        return np.ones_like(G(theta_hat_l,Hl_minus1))\n",
    "    elif a == \"sigmoid\" or a == \"softmax\":\n",
    "        return f(theta_hat_l,Hl_minus1,a)*(1-f(theta_hat_l,Hl_minus1,a))\n",
    "    elif a == \"relu\":\n",
    "        return f(theta_hat_l,Hl_minus1,a) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_Hl(theta_hat_l,Hl_minus1,a):\n",
    "    f_dash = f_prime(theta_hat_l,Hl_minus1,a)\n",
    "    f_dash = f_dash.reshape(f_dash.shape[1],f_dash.shape[0],-1)\n",
    "    Hl_minus1_T = Hl_minus1.T\n",
    "    Hl_minus1_T = Hl_minus1_T.reshape(Hl_minus1_T.shape[0],-1,Hl_minus1_T.shape[1])\n",
    "    return np.matmul(f_dash,Hl_minus1_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_J_del_Yi_hat(Yi_hat,gt_label,loss_fn):\n",
    "    if loss_fn == \"mse\":\n",
    "        return (Yi_hat - gt_label)\n",
    "    elif Yi_hat.shape[1] == 1 and loss_fn == \"cross entropy\":\n",
    "        return (Yi_hat - gt_label)/(Yi_hat * (1-Yi_hat))\n",
    "    elif Yi_hat.shape[1] > 1 and loss_fn == \"cross entropy\":\n",
    "        return -gt_label/Yi_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_J(theta_hat_lplus1,del_J_del_Hlplus1,Hl,a):\n",
    "    f_dash = f_prime(theta_hat_lplus1,Hl,a)\n",
    "    f_dash = f_dash.reshape(f_dash.shape[1],f_dash.shape[0],-1)\n",
    "    J_dash = np.matmul(theta_hat_lplus1,(del_J_del_Hlplus1*f_dash))\n",
    "    return J_dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def J(X_dash,theta_hat_initial,gt_label,activations,loss_fn):\n",
    "    \n",
    "    layer_indices = list(range(len(neurons)))\n",
    "    layer_outputs = [None]*len(layer_indices)\n",
    "    \n",
    "    layer_outputs[1] = X_dash\n",
    "    for current_layer in layer_indices[2:]:\n",
    "        layer_outputs[current_layer] = f(theta_hat_initial[current_layer],\n",
    "                                         layer_outputs[current_layer-1],activations[current_layer])\n",
    "        \n",
    "    Y_hat = layer_outputs[current_layer]\n",
    "    \n",
    "    if loss_fn == \"mse\":\n",
    "        return (1/2)*np.mean(np.linalg.norm(gt_label-Y_hat,axis=0))\n",
    "    elif Y_hat.shape[0] == 1 and loss_fn == \"cross entropy\":\n",
    "        return -(np.matmul(gt_label,np.log(Y_hat).T) + np.matmul((1-gt_label),np.log(1-Y_hat).T))/X_dash.shape[1]\n",
    "    elif Y_hat.shape[0] > 1 and loss_fn == \"cross entropy\":\n",
    "        return -np.mean(gt_label.T*np.log(Y_hat),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 10**(-2)\n",
    "epochs = 10000\n",
    "epoch_counter = 0\n",
    "loss_fn_history = list()\n",
    "layer_indices = list(range(0,len(neurons)))\n",
    "batch_size = 398"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going to code Backpropagation Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while epoch_counter < epochs:\n",
    "    \n",
    "    l = 1\n",
    "    \n",
    "    for i in range(X_dash_T.shape[0]//batch_size):\n",
    "        random_index = np.random.choice(np.arange(X_dash_T.shape[0]),size=batch_size,replace=False)\n",
    "        Xi_dash_T = X_dash_T[random_index,:]\n",
    "        Xi_dash = Xi_dash_T.reshape(Xi_dash_T.shape[1],batch_size)\n",
    "        H[l] = Xi_dash\n",
    "        \n",
    "        #The below loop is implementing Forward Propagation, computing Forward Pass Derivatives\n",
    "        #as well as computing the output of all the hidden layers including output layer\n",
    "        \n",
    "        for current_layer in layer_indices[(l+1):]:\n",
    "            frwrd_dels[current_layer] = del_Hl(theta_hat_initial[current_layer],H[current_layer-1],\n",
    "                                              activation[current_layer])\n",
    "            H[current_layer] = f(theta_hat_initial[current_layer],H[current_layer-1],\n",
    "                                 activation[current_layer])\n",
    "            \n",
    "        #The two line code below is computing the Backward Pass Derivative of the loss function wrt \n",
    "        #output of the output layer (Yi_hat)\n",
    "            \n",
    "        backwrd_dels[current_layer] = del_J_del_Yi_hat(H[current_layer],Xi_dash,\"mse\")\n",
    "        backwrd_dels[current_layer] = backwrd_dels[current_layer].reshape(batch_size,\n",
    "                                                                          backwrd_dels[current_layer].shape[0],\n",
    "                                                                          -1)\n",
    "        \n",
    "        l = current_layer\n",
    "        \n",
    "        #The below loop is implementing Backward Propagation, computing Backward Pass Derivatives of \n",
    "        #loss function wrt the output of all the hidden layers except output layer\n",
    "        \n",
    "        for current_layer in layer_indices[(l-1):1:-1]:\n",
    "            backwrd_dels[current_layer] = del_J(theta_hat_initial[current_layer+1],\n",
    "                                                backwrd_dels[current_layer+1],H[current_layer],\n",
    "                                               activation[current_layer+1])\n",
    "            \n",
    "        l = 1\n",
    "            \n",
    "        \n",
    "        #The below loop is implementing Backpropagation of Error computed by the loss function computed\n",
    "        #at the end of Neural Network Output, by adjusting the connection weight matrices from their \n",
    "        #initial guess to the final guess, using Gradient Descent Algorithm. \n",
    "        \n",
    "        for current_layer in layer_indices[(l+1):]:\n",
    "            theta_hat_initial[current_layer] = theta_hat_initial[current_layer] - epsilon*np.mean(\n",
    "                                                backwrd_dels[current_layer]*frwrd_dels[current_layer],axis=0).T\n",
    "        \n",
    "    epoch_counter = epoch_counter + 1\n",
    "    print(\"Epoch number =\",epoch_counter,\"Loss Function =\",J(X_dash_T.T,theta_hat_initial,\n",
    "                                                                         X_dash_T.T,activation,\"mse\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_encoding_matrix = theta_hat_initial[2].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_encoding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_decoding_matrix = theta_hat_initial[3].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_decoding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.matmul(trained_decoding_matrix,trained_encoding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_decoding_matrix = trained_decoding_matrix/np.linalg.norm(trained_decoding_matrix,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = trained_decoding_matrix[:,0]\n",
    "b = trained_decoding_matrix[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arccos(np.dot(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
